{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felix/.local/share/virtualenvs/Comparing-Measures-of-LLM-Truthfulness-c5kw3004/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, pipeline, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpleTQA import SimpleTQA\n",
    "from RepresentationEngineering.repe import repe_pipeline_registry\n",
    "repe_pipeline_registry()\n",
    "\n",
    "from RepresentationEngineering.examples.honesty.utils import honesty_function_dataset, plot_lat_scans, plot_detection_results "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "model = \"llama-2-7b-chat\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_token = -1\n",
    "hidden_layers = list(range(-1, -model.config.num_hidden_layers, -1))\n",
    "n_difference = 1\n",
    "direction_method = \"pca\"\n",
    "rep_reading_pipeline = pipeline(\"rep-reading\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_tag = \"USER:\"\n",
    "assistant_tag = \"ASSISTANT:\"\n",
    "\n",
    "data_path = \"RepresentationEngineering/data/facts/facts_true_false.csv\"\n",
    "dataset = honesty_function_dataset(data_path, tokenizer, user_tag, assistant_tag)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get honesty direction using representation reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "honesty_rep_reader = rep_reading_pipeline.get_directions(\n",
    "    dataset['train']['data'], \n",
    "    rep_token=rep_token, \n",
    "    hidden_layers=hidden_layers, \n",
    "    n_difference=n_difference, \n",
    "    train_labels=dataset['train']['labels'], \n",
    "    direction_method=direction_method,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_tests = rep_reading_pipeline(\n",
    "    dataset['test']['data'], \n",
    "    rep_token=rep_token, \n",
    "    hidden_layers=hidden_layers, \n",
    "    rep_reader=honesty_rep_reader,\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rep_readings(completion, important_layers=None):\n",
    "    if important_layers is None:\n",
    "        important_layers = hidden_layers\n",
    "    input_ids = tokenizer.tokenize(completion)\n",
    "    results = []\n",
    "\n",
    "    for rep_token_pos in range(-len(input_ids), 0, 1):\n",
    "        H_tests = rep_reading_pipeline(\n",
    "            completion,\n",
    "            rep_reader=honesty_rep_reader,\n",
    "            rep_token=rep_token_pos,\n",
    "            hidden_layers=hidden_layers\n",
    "        )\n",
    "        results.append(H_tests)\n",
    "\n",
    "    honesty_scores = []\n",
    "    honesty_scores_means = []\n",
    "    for pos in range(len(results)):\n",
    "        tmp_scores = []\n",
    "        tmp_scores_all = []\n",
    "        for layer in hidden_layers:\n",
    "            tmp_scores_all.append(\n",
    "                results[pos][0][layer][0] * honesty_rep_reader.direction_signs[layer][0]\n",
    "            )\n",
    "            if layer in important_layers:\n",
    "                tmp_scores.append(\n",
    "                    results[pos][0][layer][0] * honesty_rep_reader.direction_signs[layer][0]\n",
    "                )\n",
    "        honesty_scores.append(tmp_scores_all)\n",
    "        honesty_scores_means.append(np.mean(tmp_scores))\n",
    "\n",
    "    return honesty_scores, honesty_scores_means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_tqa = SimpleTQA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "honesty_scores_truth = []\n",
    "honesty_score_means_t = []\n",
    "honesty_scores_lie = []\n",
    "honesty_score_means_l = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for answer in simple_tqa[f\"{model}_answers_truth\"]:\n",
    "    honesty_scores, honesty_scores_means = get_rep_readings(answer, important_layers=None)\n",
    "    honesty_scores_truth.append(honesty_scores)\n",
    "    honesty_score_means_t.append(honesty_scores_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for answer in simple_tqa[f\"{model}_answers_lie\"]:\n",
    "    honesty_scores, honesty_scores_means = get_rep_readings(answer, important_layers=None)\n",
    "    honesty_scores_lie.append(honesty_scores)\n",
    "    honesty_score_means_l.append(honesty_scores_means)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get lie detector probabilities on simpleTQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rows for which both lie and truth logprobs were generated\n",
    "logprobs_dataset = simple_tqa[simple_tqa[f\"{model}_logprobs_difference_lie\"].notna()]\n",
    "logprobs_dataset = logprobs_dataset[logprobs_dataset[f\"{model}_logprobs_difference_truth\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logprobs_dataset[f\"{model}_logprobs_difference_lie\"] = logprobs_dataset[f\"{model}_logprobs_difference_lie\"].apply(lambda x: np.array(x))\n",
    "logprobs_dataset[f\"{model}_logprobs_difference_truth\"] = logprobs_dataset[f\"{model}_logprobs_difference_truth\"].apply(lambda x: np.array(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logprob_diffs = np.concatenate([logprobs_dataset[f\"{model}_logprobs_difference_lie\"], logprobs_dataset[f\"{model}_logprobs_difference_truth\"]])\n",
    "labels = np.concatenate([np.zeros(len(logprobs_dataset[f\"{model}_logprobs_difference_lie\"])), np.ones(logprobs_dataset[f\"{model}_logprobs_difference_truth\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"trained_classifiers/logistic_logprobs_classifier.pkl\", \"rb\") as f:\n",
    "    classifier = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, auc, _, lie_detector_pred, lie_detector_pred_proba = classifier.evaluate(logprob_diffs, labels, return_ys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lie_detector_pred_proba = np.array(lie_detector_pred_proba)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare results from RepEng with lie detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data\n",
    "x1 = lie_detector_pred_proba[labels == 1]\n",
    "y1 = honesty_score_means_t\n",
    "\n",
    "x2 = lie_detector_pred_proba[labels == 0]\n",
    "y2 = honesty_score_means_l\n",
    "\n",
    "# Create a scatter plot with different colors and labels\n",
    "plt.scatter(x1, y1, c='blue', label='Truth')\n",
    "plt.scatter(x2, y2, c='red', label='Lie')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Log(P())')\n",
    "plt.ylabel('Y-axis Label')\n",
    "plt.title('Scatter Plot with Different Colors')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Comparing-Measures-of-LLM-Truthfulness-c5kw3004",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
