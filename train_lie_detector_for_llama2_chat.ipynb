{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.calibration import CalibrationDisplay\n",
    "\n",
    "from lllm.classification_utils import Classifier, create_datasets_paired_questions as create_datasets\n",
    "from simpleFacts import SimpleFacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng=np.random.RandomState(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_facts = SimpleFacts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logprobs_dataset = simple_facts.get_logprobs_differences(return_setup=True)\n",
    "probs_dataset = simple_facts.get_probs_differences(return_setup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column with lie instruction:\n",
    "logprobs_dataset[\"lie_instruction\"] = [elem[\"lie_instruction\"] for elem in\n",
    "                                       logprobs_dataset[\"llama-2-7b-chat_probes_setup\"]]\n",
    "# add a column with truth instruction:\n",
    "logprobs_dataset[\"truth_instruction\"] = [elem[\"truth_instruction\"] for elem in\n",
    "                                         logprobs_dataset[\"llama-2-7b-chat_probes_setup\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lie_instructions_list = logprobs_dataset[\"lie_instruction\"].unique()\n",
    "truth_instructions_list = logprobs_dataset[\"truth_instruction\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy array\n",
    "logprobs_dataset.iloc[:, 0] = logprobs_dataset.iloc[:, 0].apply(lambda x: np.array(x))\n",
    "logprobs_dataset.iloc[:, 1] = logprobs_dataset.iloc[:, 1].apply(lambda x: np.array(x))\n",
    "probs_dataset.iloc[:, 0] = probs_dataset.iloc[:, 0].apply(lambda x: np.array(x))\n",
    "probs_dataset.iloc[:, 1] = probs_dataset.iloc[:, 1].apply(lambda x: np.array(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_logprobs, X_test_logprobs, train_instructions, test_instructions, train_datasets, test_datasets, X_train_probs, X_test_probs, y_train, y_test = create_datasets(logprobs_dataset, probs_dataset, rng=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_classifier = Classifier(X_train_logprobs, y_train, random_state=rng)\n",
    "accuracy, auc, conf_matrix = log_reg_classifier.evaluate(X_test_logprobs, y_test)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"AUC: {auc}\")\n",
    "print(f\"Confusion matrix: {conf_matrix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = log_reg_classifier.predict_proba(X_test_logprobs)\n",
    "calibration_display = CalibrationDisplay.from_predictions(y_test, y_pred_proba, n_bins=20, name=\"LogReg\", strategy=\"quantile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_pred_proba, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"trained_classifiers/logistic_logprobs_classifier.pkl\", \"wb\") as f:\n",
    "        pickle.dump(log_reg_classifier, f)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
